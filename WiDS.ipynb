{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WiDS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPU5bxZBp+44Lm77W4tbZk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SophiaHe/WomenInDSComp/blob/master/WiDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WyRLBAiEdwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import unique\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Preprocessing, modelling and evaluating\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Imputer\n",
        "#from sklearn.preprocessing import Imputer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        "!pip install dplython\n",
        "from dplython import (DplyFrame, X, diamonds, select, sift, sample_n,\n",
        "    sample_frac, head, arrange, mutate, group_by, summarize, DelayFunction) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3owiHUHR4CH",
        "colab_type": "code",
        "outputId": "4b95193b-4e5b-4056-c317-a48a2a7e9bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dplython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/47/504439b206268ebe249de52fa44a9b7d7a1a05b1d75ed443fb5af3b660cf/dplython-0.0.7.tar.gz (715kB)\n",
            "\u001b[K     |████████████████████████████████| 716kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dplython) (1.17.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from dplython) (0.25.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from dplython) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->dplython) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->dplython) (2.6.1)\n",
            "Building wheels for collected packages: dplython\n",
            "  Building wheel for dplython (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dplython: filename=dplython-0.0.7-cp36-none-any.whl size=747244 sha256=32eb60d5def31a1f68b8a0286acc4eb9b59c43b158b347db78d0517bf5a387ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/c5/dc/06ed265021b09111a8e7bd7f7577656a64e1293c10df09e0f5\n",
            "Successfully built dplython\n",
            "Installing collected packages: dplython\n",
            "Successfully installed dplython-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nty99Sh-HtoJ",
        "colab_type": "code",
        "outputId": "1a2962fb-ffe2-4902-fa6e-2861e7d39985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "train = pd.read_csv(\"training_v2.csv\")\n",
        "test = pd.read_csv(\"unlabeled.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5e528017ed51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_v2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unlabeled.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'training_v2.csv' does not exist: b'training_v2.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5G6KpgxPiR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras\n",
        "X =  train[['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', \n",
        "'icu_stay_type', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem']]\n",
        "y = train['hospital_death']\n",
        "# retrieve numpy array\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "# train_dataset[0:2,-1]\n",
        "\n",
        "# format all fields as string\n",
        "X = X.astype(str)\n",
        "# reshape target to be a 2d array\n",
        "y = y.reshape((len(y), 1))\n",
        "\n",
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "\tX_train_enc, X_test_enc = list(), list()\n",
        "\t# label encode each column\n",
        "\tfor i in range(X_train.shape[1]):\n",
        "\t\tle = LabelEncoder()\n",
        "\t\t# le.fit_transform(X_train[:, i])\n",
        "\t\t# encode\n",
        "\t\ttrain_enc = le.fit_transform(X_train[:, i])\n",
        "\t\ttest_enc = le.fit_transform(X_test[:, i])\n",
        "\t\t# store\n",
        "\t\tX_train_enc.append(train_enc)\n",
        "\t\tX_test_enc.append(test_enc)\n",
        "\treturn X_train_enc, X_test_enc\n",
        "\n",
        "# prepare target\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tle = LabelEncoder()\n",
        "\t#le.fit(y_train)\n",
        "\ty_train_enc = le.fit_transform(y_train)\n",
        "\ty_test_enc = le.fit_transform(y_test)\n",
        "\treturn y_train_enc, y_test_enc\n",
        "\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# prepare input data\n",
        "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
        "# prepare output data\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
        "# make output 3d\n",
        "y_train_enc = y_train_enc.reshape((len(y_train_enc), 1, 1))\n",
        "y_test_enc = y_test_enc.reshape((len(y_test_enc), 1, 1))\n",
        "\n",
        "# prepare each input head\n",
        "in_layers = list()\n",
        "em_layers = list()\n",
        "for i in range(len(X_train_enc)):\n",
        "\t# calculate the number of unique inputs\n",
        "\tn_labels = len(unique(X_train_enc[i]))\n",
        "\t# define input layer\n",
        "\tin_layer = Input(shape=(1,))\n",
        "\t# define embedding layer\n",
        "\tem_layer = Embedding(n_labels, 10)(in_layer)\n",
        "\t# store layers\n",
        "\tin_layers.append(in_layer)\n",
        "\tem_layers.append(em_layer)\n",
        "# concat all embeddings\n",
        "merge = concatenate(em_layers)\n",
        "dense = Dense(10, activation='relu', kernel_initializer='he_normal')(merge)\n",
        "output = Dense(1, activation='sigmoid')(dense)\n",
        "model = Model(inputs=in_layers, outputs=output)\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# plot graph\n",
        "plot_model(model, show_shapes=True, to_file='embeddings.png')\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train_enc, y_train_enc, epochs=20, batch_size=16, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBZMv27PUyaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X =  test[['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', \n",
        "'icu_stay_type', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem']]\n",
        "\n",
        "# retrieve numpy array\n",
        "X = X.values\n",
        "\n",
        "# prepare input data\n",
        "def prepare_inputs2( X_test):\n",
        "\tX_test_enc =  list()\n",
        "\t# label encode each column\n",
        "\tfor i in range(X_test.shape[1]):\n",
        "\t\tle = LabelEncoder()\n",
        "\n",
        "\t\ttest_enc = le.fit_transform(X_test[:, i])\n",
        "\t\t# store\n",
        "\t\tX_test_enc.append(test_enc)\n",
        "\treturn X_test_enc\n",
        "# format all fields as string\n",
        "X = X.astype(str)\n",
        "# prepare input data\n",
        "X_test_enc2 = prepare_inputs2(X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypnujEcGQ48n",
        "colab_type": "code",
        "outputId": "4c73d9ac-f5a5-40cf-fc7e-e8662e4930f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "len(X_test_enc2[0])\n",
        "\n",
        "X_train_enc_pred =model.predict(X_train_enc)\n",
        "for i in range(5):\n",
        "\tprint(\"X=%s, Predicted=%s\" % (X_train_enc[i], y_train_enc[i]))\n",
        " X_test_enc_pred =model.predict(X_test_enc2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 91.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ_VER1iVywG",
        "colab_type": "code",
        "outputId": "4ba3d3ee-2c39-4001-8fcc-0c624afded42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "X_test_enc_pred = X_test_enc_pred.reshape(-1, 1)\n",
        "\n",
        "print(X_test_enc_pred[0:3])\n",
        "from numpy import savetxt\n",
        "savetxt('NN_CatOnly.csv', X_test_enc_pred, delimiter=',')\n",
        "# kaggle score: 0.66"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.08629763]\n",
            " [0.01023304]\n",
            " [0.00761101]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I62nKTEua7cV",
        "colab_type": "text"
      },
      "source": [
        "CNN using numeric variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8I2Dj2a-nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU \n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "np.random.seed(2017)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yntKZj6FFB_e",
        "colab_type": "code",
        "outputId": "28eb62dd-8601-4485-a7d8-a2c0b679d678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# delete columns with >60% missing values\n",
        "# train = train.drop(['patient_id', 'hospital_id','icu_id', 'encounter_id'], axis=1)\n",
        "# test = test.drop(['patient_id', 'hospital_id','icu_id', 'encounter_id'], axis=1)\n",
        "\n",
        "cols_to_delete = train.columns[train.isnull().sum()/len(train) > .60]\n",
        "cols_to_delete2 = test.columns[test.isnull().sum()/len(test) > .60]\n",
        "cols_to_delete_final = cols_to_delete.intersection(cols_to_delete2)\n",
        "\n",
        "print(len(cols_to_delete)) # 66\n",
        "print(len(cols_to_delete2)) # 68\n",
        "print(len(cols_to_delete.intersection(cols_to_delete2))) # 66 overlaps\n",
        "\n",
        "train.drop(cols_to_delete_final, axis = 1, inplace = True)\n",
        "test.drop(cols_to_delete_final, axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n",
            "68\n",
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ2eEqo2Gh1r",
        "colab_type": "code",
        "outputId": "6cfb4add-6b33-4c3e-e48d-1cd110687924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "train2 = train.select_dtypes(include=numerics)\n",
        "test2 = test.select_dtypes(include=numerics)\n",
        "print(train2.shape)\n",
        "print(test2.shape)\n",
        "\n",
        "X_train = train2.loc[:, train2.columns != 'hospital_death']\n",
        "y_train = train2['hospital_death']\n",
        "\n",
        "X_test = test2.loc[:, test2.columns != 'hospital_death']\n",
        "y_test = test2['hospital_death']\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91713, 108)\n",
            "(39308, 108)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ_IE45LWWW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary Classification with Sonar Dataset: Baseline\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = train2.loc[:, train2.columns != 'hospital_death']\n",
        "y = train2['hospital_death']\n",
        "\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(107, input_dim=107, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, X, y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECDbI8gLIATC",
        "colab_type": "code",
        "outputId": "810d1df3-b1d0-4037-9d12-73f9e42e90d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "X_train = X_train.as_matrix()\n",
        "X_train = np.reshape(X_train[:,1:108],(53,114,1609,1))\n",
        "\n",
        "y_train = y_train.as_matrix()\n",
        "print(y_train.shape)\n",
        "print(X_train.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91713,)\n",
            "(53, 114, 1609, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQwgBJUOYrOI",
        "colab_type": "code",
        "outputId": "64ee8f18-594d-4b91-cd62-d648037c20b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# X_test = X_test.as_matrix()\n",
        "X_test = np.reshape(X_test[:,1:108],(248,53,317,1))\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(248, 53, 317, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ctNLXWiH-OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 2)\n",
        "\n",
        "\n",
        "print('train labels:\\t',Y_train.shape)\n",
        "print(Y_train[0:10, :])\n",
        "\n",
        "trainX_normal = (X_train/255.)\n",
        "testX_normal = (X_test/255.)\n",
        "\n",
        "trainX_normal = trainX_normal.astype('float32')\n",
        "testX_normal = testX_normal.astype('float32')\n",
        "\n",
        "print('train)\\tmin: ', np.min(trainX_normal), '\\tmax: ', np.max(trainX_normal))\n",
        "print('test)\\tmin: ', np.min(testX_normal), '\\tmax: ', np.max(testX_normal))\n",
        "print(trainX_normal.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}